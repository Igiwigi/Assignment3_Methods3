---
title: "Assignment 3 - Diagnosing Schizophrenia from Voice"
subtitle: 'Instructions'
output:
  html_document:
      toc: yes
      number_sections: yes
      toc_float: yes
      theme: united
      highlight: espresso
      css: 'scripts/standard.css'
geometry: margin=1in
knit: (function(inputFile, encoding) {
  browseURL(
    rmarkdown::render(
      inputFile,
      encoding = encoding,
      output_dir = 'documents/',
      output_file = "assignment3_diagnosing_schizophrenia.html"))})
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(pacman)
p_load(
  tidyverse,
  ggplot2,
  dplyr,
  caret,
  parsnip,
  pROC,
  ranger
)
```

This assignment is based on the following paper:

[Parola A et al. 2023. Voice Patterns as Markers of Schizophrenia: Building a Cumulative Generalizable Approach Via a Cross-Linguistic and Meta-analysis Based Investigation. Schizophrenia Bulletin 22(49):S125-S141.](https://doi.org/10.1093/schbul/sbac128)

Individuals with schizophrenia (SCZ) tend to present voice atypicalities. Their tone is described as "inappropriate" voice, sometimes monotone, sometimes croaky. This is important for two reasons. First, voice could constitute a direct window into cognitive, emotional, and social components of the disorder, thus providing a cheap and relatively non-invasive way to support the diagnostic and assessment process (via automated analyses). Secondly, voice atypicalities play an important role in the social impairment experienced by individuals with SCZ, and are thought to generate negative social judgments (of unengaged, slow, unpleasant interlocutors), which can cascade in more negative and less frequent social interactions.

While several studies show significant differences in acoustic features by diagnosis, we want to know whether we can diagnose SCZ in participants only from knowing the features of their voice. 

To that end, the authors collected data from various relevant studies. The latter focused on analyzing voice recordings from people that just got a first diagnosis of schizophrenia, along with a 1:1 case-control sample of participants with matching gender, age, and education. 

Each participant watched several videos (here called trials) of triangles moving across the screen and had to describe them, so you have several recordings per person. 
Along with these files, pitch was recorded once every 10 milliseconds for each participant and various duration-related statistics were also collected (e.g. number of pauses). 

For the purpose of this assignment, studies conducted in languages other than Danish were filtered out.

Your main task for this assignment will be to replicate this research project through the design, fit, and reporting of unsupervised learning methods. More precisely, this assignment will consist in:

  1. Collecting and cleaning the project data
  2. Understanding the data using descriptive statistics
  3. Predicting diagnosis using supervised learning procedures
  4. Discussion on the methods and the results

The following sections will address these objectives in order. You can complete each section in the way that best fits you. However, we remind you that proceeding methodically by segmenting your code in multiple, thematically-organised code chunks will greatly help you mane the whole modeling procedure.

# Collecting and cleaning the project data

There are two different data sets for this assignment:

1. **articulation_data.txt**. This file contains all duration-related data collected from the participants to the different studies included in the project. Here is a short description of its linguistic variables.

  - *nsyll:* number of syllables automatically inferred from the audio
  - *npause:* number of pauses automatically inferred from the audio (absence of human voice longer than 200 milliseconds)
  - *dur (s):* duration (in seconds) of the full recording
  - *phonationtime (s):* duration (in seconds) of the recording where speech is present
  - *speechrate (nsyll/dur):**average number of syllables per second
  - *articulation rate (nsyll/ phonationtime):* average number of syllables per second where speech is present
  - *ASD (speakingtime/nsyll):* average syllable duration

```{r import_articulation_data}
art_data <- read.table("../data/articulation_data.txt", header = T, fill = T)
p_data <- read.table("../data/pitch_data.txt", header = T, fill = T)
```


2. **pitch_data.txt**. Aggregated pitch data collected from the participants to the different studies included in the project. Fundamental pitch frequency was recorded for each participant every 10 milliseconds (excluding pauses) and aggregated at the participant trial level with the use of various centrality and dispersion measures. While most column names are self-explanatory, the following might be hard to figure out:

  - *iqr:* Interquartile range
  - *mad:* Mean absolute deviation
  - *coefvar:* Coefficient of variation


```{r cleaning_up_data_for_merge}
#mutating diagnosis for myself
p_data <- p_data %>%
  mutate(Diagnosis = if_else(Diagnosis == "control", "CTRL", "SCZ" ))

#getting rid of useless columns
art_data <- art_data %>%
  select(-study, -phonationtime., -X.speakingtime.nsyll., -PauseDuration, -ID, -Study, -Trial, -Diagnosis, -ASD)

#changing the column names to what they ought be for the merge
art_data <- art_data %>%
  #these are already present in the data but wrongly named
  rename(Trial = X.nsyll)%>%
  rename(ID = rate)%>%
  rename(Diagnosis = articulation)%>%
  rename(Study = X.nsyll.dur.) %>%
  #adding the two new values that are missing but can be inferred from data?
  mutate(articulationrate = (nsyll/phonationtime))%>%
  #is this correct? *ASD (speakingtime/nsyll):* average syllable duration
  #but there is no direct speakingtime unless that is speechrate?
  mutate(ASD = (speechrate/nsyll)) %>%
  #naming to match the naming convention
  mutate(Diagnosis = if_else(Diagnosis == "control", "CTRL", "SCZ" ))

#renaming more to make them pitch-distinct and more convenient for me
p_data <- p_data %>%
rename(p_mean = mean) %>%
rename(p_sd = sd) %>%
rename(p_min = min) %>%
rename(p_max = max) %>%
rename(p_median = median) %>%
rename(p_iqr = iqr)%>%
rename(p_mad = mad) %>%
rename(p_coefvar = coefvar)

#renaming more for my own convenience
art_data <- art_data %>%
rename(full_dur = dur)


#should we choose only the relevant columns, are means, mins, maxes, etc. relevant if not listed??
p_data <- p_data %>%
  select(ID, Diagnosis, Study, Trial, p_iqr, p_mad, p_coefvar, p_mean, p_sd, p_min, p_max, p_median )
art_data <- art_data %>%
    select(ID, Diagnosis, Study, Trial, nsyll, npause, full_dur, phonationtime, speechrate, articulationrate, ASD)
```

```{r data_refactoring}
#i assume these to be important as factor; can change it later
p_data$Diagnosis <- as.factor(p_data$Diagnosis)
p_data$Study <- as.factor(p_data$Study)
p_data$Trial <- as.factor(p_data$Trial)
p_data$ID <- as.factor(p_data$ID)

art_data$Diagnosis <- as.factor(art_data$Diagnosis)
art_data$Study <- as.factor(art_data$Study)
art_data$Trial <- as.factor(art_data$Trial)
art_data$ID <- as.factor(art_data$ID)
```

After importing the data sets, make sure all common columns and values are named accordingly. Finally, merge the data sets on the appropriate columns, rename columns and values to your liking, and save the resulting data set using a file name and path of your own choosing.

```{r merge_and_save}
#hopefully correctly merged
df <- left_join(p_data, art_data, by = c("ID", "Study", "Trial", "Diagnosis"))
write.csv(df, "../data/merged_data.csv", row.names = FALSE)
```

# Understanding the sample using descriptive statistics

In this section, use whatever statistical procedures you think relevant to get a good understanding of the data set, particularly as regards to the differences between linguistic markers of neurotypical and schizophrenic speech. Here as in the following sections, make sure that we understand what you're doing and why you're doing it (you can do this by adding text right before or after the corresponding chunk of code).

Here are some of the things you can do:
  - Describe the data set (number of studies, number of participants, age, gender, clinical and cognitive features of the two groups) and assess whether the groups (schizophrenia and controls) are balanced.
  - Describe the acoustic profile of a schizophrenic voice: which features are different? E.g. People with schizophrenia tend to have high-pitched voice. 

```{r summarize_dataset, warning = F, error= F}
#exploring the dataset 

df %>%
  group_by(Diagnosis) %>%
  summarize(Count = n())
#ratio between diagnoses seems balanced enough, though not perfectly 50/50

df %>%
  group_by(Diagnosis, Study) %>%
  summarize(Count = n())
#fairly balanced though for some reason big difference between Study 3 for SCZ and CTRL (151 vs 232)

df %>%
  group_by(Diagnosis, Trial) %>%
  summarize(Count = n())
#appears balanced enough

df %>%
  group_by(Diagnosis)%>%
  summarize(across(c(speechrate, phonationtime, articulationrate, ASD, npause, nsyll), mean))
#SCZ speak less overall: 
#less syllables per second = speechrate
#less speech present in recording = phonationtime (seems significant at a glance!!)
#slightly? less syllabes per second where speech is present = articulationrate
#articulate syllables much slower = ASD (seems significant at a glance!!)
#take slightly? more pauses
#speak less syllables (seems significant at a glance!!)

#doing a quick and dirty t-test to "confirm" the assumptions made at a glance (assuming non-normality so wilcox)
df %>%
  group_by(Diagnosis) %>%
  summarise(across(where(is.numeric), ~ wilcox.test(.x ~ as.factor(Diagnosis), data = df)$p.value)) %>%
  select_if(function(x) any(x < 0.05))

#most columns are "statistically significant" as in, from different populations (this being a difference between the diagnoses) (not counting the means, which makes sense)

#namely, pitch interquartile range, pitch mean absolute deviation and pitch coefficient of variation, pitch max (do SCZ speak either high or low pitch?)
#meaning that the pitch is significantly different between the diagnoses

#number of syllables spoken overall, phonationtime (how much is spoken), the rate of speech and syllable articulation speed are also highly relevant

#also variables related to pauses are significant
```
```{r old-version, echo=F}
#OLD
ggplot(df, aes(x = Diagnosis, y = p_max, fill = Diagnosis)) +
geom_violin(trim = T) +
  labs(x = "Diagnosis", y = "Maximum pitch") +
  ggtitle("Max Pitch by Diagnosis") +
  theme_minimal() +
stat_summary(fun.data="mean_sdl",geom="crossbar", width=0.02 )+
  scale_fill_manual(values = c("SCZ" = "gray", "CTRL" = "white"))+
  geom_text(data = means, aes(label = paste("Mean:", round(mean_pitchmax, 2)), x = Diagnosis, y = mean_pitchmax), vjust = -7, hjust = -0.1, size = 4)
#pitch differs between groups apparently statistically significantly? CTRL individuals have higher pitch, but could also be related to gender, SCZ density plot has a fatter "bottom" visually

ggplot(df, aes(x = Diagnosis, y = p_max, fill = Diagnosis)) +
  geom_violin(trim = TRUE) +
  ylim(0, max(df$p_max)) +
  labs(x = "Diagnosis", y = "Maximum pitch") +
  ggtitle("Max Pitch by Diagnosis") +
  theme_minimal() +
  stat_summary(
    fun.data = function(x) {
      mean_val <- mean(x)
      sd_val <- sd(x)
      ymin_val <- max(0, mean_val - sd_val)
      ymax_val <- mean_val + sd_val
      return(data.frame(y = mean_val, ymin = ymin_val, ymax = ymax_val))
    },
    geom = "crossbar",
    width = 0.02
  ) +
  scale_fill_manual(values = c("SCZ" = "gray", "CTRL" = "white")) +
  geom_text(
    data = means,
    aes(label = paste("Mean:", round(mean_pitchmax, 2)), x = Diagnosis, y = mean_pitchmax),
    vjust = -7,
    hjust = -0.1,
    size = 4
  )
```
#make a function of this shit maybe
```{r summarize_dataset_visually}
# geom_text(data = means, aes(label = paste("Mean:", round(mean_ASD, 2)), x = Diagnosis, y = mean_ASD), vjust = -1, hjust = 0.5, size = 4) + 
  
means <- df %>%
  group_by(Diagnosis) %>%
  summarize(mean_ASD = mean(ASD), mean_nsyll = mean(nsyll), mean_npause = mean(npause), mean_pitchmax = mean(p_max), mean_phonationtime = mean(phonationtime), mean_speechrate = mean(speechrate))

ggplot(df, aes(x = Diagnosis, y = ASD, fill = Diagnosis)) +
geom_violin(trim = T) +
ylim(0,max(df$ASD))+
labs(x = "Diagnosis", y = "AVG Syllable Duration") +
ggtitle("Average Syllable Duration by Diagnosis") +
theme_minimal() +
  scale_fill_manual(values = c("SCZ" = "gray", "CTRL" = "white"))+
  geom_text(data = means, aes(label = paste("Mean:", round(mean_ASD, 2)), x = Diagnosis, y = mean_ASD), vjust = -7, hjust = -0.3, size = 4)+
stat_summary(fun = "max", geom = "point", size = 3, position = position_dodge(width = 0.75), color = "black")+
    stat_summary(
    fun.data = function(x) {
      mean_val <- mean(x)
      sd_val <- sd(x)
      ymin_val <- max(0, mean_val - sd_val)
      ymax_val <- mean_val + sd_val
      return(data.frame(y = mean_val, ymin = ymin_val, ymax = ymax_val))
    },
    geom = "crossbar",
    width = 0.02
  ) 
#maybe omit the most extreme of values? theres an extreme high average syllable duration, perhaps a different reason for it

ggplot(df, aes(x = Diagnosis, y = p_max, fill = Diagnosis)) +
  geom_violin(trim = TRUE) +
  ylim(0, max(df$p_max)) +
  labs(x = "Diagnosis", y = "Maximum pitch") +
  ggtitle("Max Pitch by Diagnosis") +
  theme_minimal() +
  stat_summary(
    fun.data = function(x) {
      mean_val <- mean(x)
      sd_val <- sd(x)
      ymin_val <- max(0, mean_val - sd_val)
      ymax_val <- mean_val + sd_val
      return(data.frame(y = mean_val, ymin = ymin_val, ymax = ymax_val))
    },
    geom = "crossbar",
    width = 0.02
  ) +
  scale_fill_manual(values = c("SCZ" = "gray", "CTRL" = "white")) +
  geom_text(
    data = means,
    aes(label = paste("Mean:", round(mean_pitchmax, 2)), x = Diagnosis, y = mean_pitchmax),
    vjust = -7,
    hjust = -0.1,
    size = 4
  )
#pitch differs between groups apparently statistically significantly? CTRL individuals have higher pitch, but could also be related to gender, SCZ density plot has a fatter "bottom" visually

ggplot(df, aes(x = Diagnosis, y = nsyll, fill = Diagnosis)) +
  geom_violin() +
  labs(x = "Diagnosis", y = "Number of Syllables") +
  ggtitle("Number of Syllables Spoken by Diagnosis") +
  theme_minimal()+
    stat_summary(
    fun.data = function(x) {
      mean_val <- mean(x)
      sd_val <- sd(x)
      ymin_val <- max(0, mean_val - sd_val)
      ymax_val <- mean_val + sd_val
      return(data.frame(y = mean_val, ymin = ymin_val, ymax = ymax_val))
    },
    geom = "crossbar",
    width = 0.02
  )+
  scale_fill_manual(values = c("SCZ" = "gray", "CTRL" = "white"))+
  geom_text(data = means, aes(label = paste("Mean:", round(mean_nsyll, 2)), x = Diagnosis, y = mean_nsyll), vjust = -7, hjust = -0.1, size = 4)
#SCZ individuals speak less syllables, SCZ density plot has a fatter "bottom" visually

ggplot(df, aes(x = Diagnosis, y = phonationtime, fill = Diagnosis)) +
  geom_violin() +
  labs(x = "Diagnosis", y = "Phonation time") +
  ggtitle("Phonation Time by Diagnosis") +
  theme_minimal()+
    stat_summary(
    fun.data = function(x) {
      mean_val <- mean(x)
      sd_val <- sd(x)
      ymin_val <- max(0, mean_val - sd_val)
      ymax_val <- mean_val + sd_val
      return(data.frame(y = mean_val, ymin = ymin_val, ymax = ymax_val))
    },
    geom = "crossbar",
    width = 0.02
  ) +
  scale_fill_manual(values = c("SCZ" = "gray", "CTRL" = "white"))+
  geom_text(data = means, aes(label = paste("Mean:", round(mean_phonationtime, 2)), x = Diagnosis, y = mean_phonationtime), vjust = -7, hjust = -0.3, size = 4)
#overall, SCZ individuals speak less in the recording, density plot appears fairly similar, however

ggplot(df, aes(x = Diagnosis, y = speechrate, fill = Diagnosis)) +
  geom_violin() +
  labs(x = "Diagnosis", y = "AVG of syllables spoken per second") +
  ggtitle("AVG number of syllables per second by Diagnosis") +
  theme_minimal()+
    stat_summary(
    fun.data = function(x) {
      mean_val <- mean(x)
      sd_val <- sd(x)
      ymin_val <- max(0, mean_val - sd_val)
      ymax_val <- mean_val + sd_val
      return(data.frame(y = mean_val, ymin = ymin_val, ymax = ymax_val))
    },
    geom = "crossbar",
    width = 0.02
  ) +
  scale_fill_manual(values = c("SCZ" = "gray", "CTRL" = "white"))+
  geom_text(data = means, aes(label = paste("Mean:", round(mean_speechrate, 2)), x = Diagnosis, y = mean_speechrate), vjust = -7, hjust = -0.3, size = 4)
#an extreme value in SCZ

ggplot(df, aes(x = Diagnosis, y = npause, fill = Diagnosis)) +
  geom_violin() +
  labs(x = "Diagnosis", y = "Pauses n") +
  ggtitle("Number of pauses by Diagnosis") +
  theme_minimal()+
    stat_summary(
    fun.data = function(x) {
      mean_val <- mean(x)
      sd_val <- sd(x)
      ymin_val <- max(0, mean_val - sd_val)
      ymax_val <- mean_val + sd_val
      return(data.frame(y = mean_val, ymin = ymin_val, ymax = ymax_val))
    },
    geom = "crossbar",
    width = 0.02
  ) +
  scale_fill_manual(values = c("SCZ" = "gray", "CTRL" = "white"))+
  geom_text(data = means, aes(label = paste("Mean:", round(mean_npause, 2)), x = Diagnosis, y = mean_npause), vjust = -7, hjust = -0.3, size = 4)
#an extreme value in SCZ, fatter bottom on SCZ density plot


#Visually it appears that the "shape" i.e. density of both SCZ and CTRL violin plots appears fairly similar, meaning that the potential difference with SCZ speech variables is more-so the range of values, not their distribution. That said, some of the SCZ plots had a fatter "bottom", meaning that more of the data points fall on the low side of things.
#But visually *fairly* similar is not *the same*, might just convey that both categories are human-data (shared, overlapping distribution of being human or something along those lines)? but if enough data, wouldn't that approach normality?
```


# Predicting diagnosis using supervised learning procedures

We now want to know whether we can automatically diagnose schizophrenia from voice alone. To do this, we will proceed in incremental fashion. We will first start by building a simple random forest model, add an optimized version, and then add a third model based on an algorithm of your choice. Once again, we ask that you connect the different code chunks you create with short descriptive/explanatory text segments that gives us an idea about what you are doing and why you are doing it.

The following packages will be useful to you here:

  - [**tidymodels**](https://tidymodels.tidymodels.org/): “meta-package” for modeling and statistical analysis that shares the underlying design philosophy, grammar, and data structures of the tidyverse.
  - [**rsample**](https://rsample.tidymodels.org/): as infrastructure for resampling data so that models can be assessed and empirically validated.
  -[**groupdata2**][(https://cran.r-project.org/web/packages/groupdata2/vignettes/introduction_to_groupdata2.html)]: an alternative to rsample that allows resampling with deeper grouping
  - [**tune**](https://tune.tidymodels.org/): contains the functions to optimize model hyper-parameters.
  - [**dials**](https://dials.tidymodels.org/): tools to create and manage values of tuning parameters.
  - [**recipes**](https://recipes.tidymodels.org/index.html): a general data preprocessor that can create model matrices incorporating feature engineering, imputation, and other tools.
  - [**workflows**](https://workflows.tidymodels.org/): methods to combine pre-processing steps and models into a single object.
  - [**workflowsets**](https://workflowsets.tidymodels.org/): can create a workflow set that holds multiple workflow objects, allowing users to create and easily fit a large number of models. 
  - [**parsnip**](https://parsnip.tidymodels.org/): a tidy, unified interface to creating models 
  - [**yardstick**](https://yardstick.tidymodels.org/): contains tools for evaluating models

Finally, here are some online resources that can help you with the modeling process:

  - This [**Tidymodels tutorial**](https://www.tidymodels.org/start/) written by the Tidymodels team
  - This [**workshop on Tidymodels**](https://workshops.tidymodels.org/) written by the Tidymodels team
  - This [**workshop on Tidymodels**](https://apreshill.github.io/tidymodels-it/) written by the Posit Team (The company behind RStudio)
  - This [**online course on supervised machine learning**](https://supervised-ml-course.netlify.app/) written by the Tidymodels team

## First phase: Random Forest Model

In this phase, you will build a simple random forest model, by:

  - Splitting the data in training and testing sets
  - Training a random forest model on the training set
  - Testing the model's predictions on the testing set
  - Building the confusion matrix
  - Compiling performance metrics of your own choosing.
  

```{r simple_model-training_testing_set}
set.seed(123)

train_indices <- createDataPartition(df$Diagnosis, p = 0.7, list = FALSE)
training_set <- as.data.frame(df[train_indices, ])
testing_set <- as.data.frame(df[-train_indices, ])
```


```{r simple_model-checking_train-test_ratio}
prop_train <- table(training_set$Diagnosis) / nrow(training_set)
prop_test <- table(testing_set$Diagnosis) / nrow(testing_set)
orig <- table(df$Diagnosis) / nrow(df)

cat("Proportions in Training Set:\n", paste(names(prop_train), prop_train, sep = ": "), "\n\n")
cat("Proportions in Testing Set:\n", paste(names(prop_test), prop_test, sep = ": "), "\n\n")
cat("Proportions in OG set:\n", paste(names(orig), orig, sep = ": "), "\n\n")
#close enough to the split of Diagnosis in the original set, appears validly split into test and training
#still doesnt account for the split of study, training, other variables (could still be a bad training or testing set)
```


```{r training_and_predicting_simple_model}
rf_model <- rand_forest(
  mode = "classification",
  mtry = NULL, 
  trees = 100, 
  min_n = 5
) %>%
  set_engine("ranger") %>% 
  fit(Diagnosis ~ ., data = training_set)

predictions <- predict(rf_model, new_data = testing_set)
```


```{r testing_simple_model_metrics}
conf_matrix <- confusionMatrix(predictions$.pred_class, testing_set$Diagnosis)
conf_matrix

#a bunch of metrics from carot package
accuracy <- conf_matrix$overall["Accuracy"]
precision <- conf_matrix$byClass["Precision"]
recall <- conf_matrix$byClass["Sensitivity"]
f1_score <- (2 * precision * recall) / (precision + recall)
specificity <- conf_matrix$byClass["Specificity"]
roc_auc <- roc(testing_set$Diagnosis, as.numeric(predictions$.pred_class))$auc
#fix this error

#metrics, dont understand all of them yet, i.e. Precision = True Positives/(true positives + false positives)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))
print(paste("Precision:", round(precision, 2)))
print(paste("Recall:", round(recall, 2)))
print(paste("F1 Score:", round(f1_score, 2)))
print(paste("Specificity:", round(specificity, 2)))
print(paste("AUC-ROC:", round(roc_auc, 2)))
#70% seems ok for accuracy but could be better?
```

## Second phase: Forest Engineering

In this section, you will try to optimize the performance of the model developed in the previous phase by adding a new random forest model, upgraded with feature engineering and parameter tuning procedures of your own choosing.
#feature engineering!
#parameter tuning procedures!

```{r optimize_model}

# Copy and paste this code chunk to add further code to this section
# Remember to change the name of the chunk!

```

## Third phase: Another Algorithm

For this final part, add a supervised algorithm to the workflow set and compare its performance to the previous ones. Here again, you are free to choose any algorithm, but it its important that we know what you're doing and why you are doing it. In other words, tell us a bit about the algorithm you're using and why you chose it.

For a detailed list of the model types, engines, and arguments that can be used with the tidymodels framework, have a look here https://www.tidymodels.org/find/parsnip/#models


```{r new_model}

# Copy and paste this code chunk to add further code to this section
# Remember to change the name of the chunk!

```


# Discussion: Methodology and Results

Finally, briefly summarize and discuss the methodological choices you've made throughout as well as the results obtained at the different modeling stages. In particular, I would like to get your input as regards to the following questions:

  - Based on the performance evaluation of your models, do you think the second and third phase of the third section were worth the extra effort? Was any model successful in diagnosing schizophrenia from voice?
  - How do the predictive models you built relate to the descriptive analysis conducted in the second section?
  - What is the explanatory scope of the analyses and procedures you conducted here, if any?

> Write your report here
